---
title: "lab2_3"
output: html_document
date: "2022-11-22"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r pressure, echo=FALSE}
rm(list = ls(all = TRUE))
graphics.off()
shell("cls")

data = read.csv(file = "communities.csv",
                header = TRUE)

index <- names(data) %in% "ViolentCrimesPerPop"

data.scaled <- scale(x = data[, !index], 
                     center = TRUE, 
                     scale = TRUE)

e = eigen(cov(data[, -1]))

e.scaled = eigen(cov(data.scaled))

cum_var = cumsum(e.scaled$values/sum(e.scaled$values))
sum(cum_var<0.95)
e.scaled$values[1:2]/sum(e.scaled$values)


```

95% at 35, 25% and 17% (16.9)

```{r pressure,warning=FALSE, echo=FALSE}
data = read.csv(file = "communities.csv",
                header = TRUE)

index <- names(data) %in% "ViolentCrimesPerPop"

data.scaled <- scale(x = data[, !index], 
                     center = TRUE, 
                     scale = TRUE)
pr=princomp(data.scaled)
lambda=pr$sdev^2
#eigenvalues
lambda
#proportion of variation
sprintf("%2.3f",lambda/sum(lambda)*100)
screeplot(pr)

ev1 = pr$loadings[,1]

ev1[order(abs(ev1),decreasing = TRUE)[1:5]]


library(ggfortify)

autoplot(pr, data = data, colour = "ViolentCrimesPerPop")

```
Yes many features seem to have a relativly big contribution.

The 5 values sound reasonable and should have a 
logical relationship to the crime level

the area up to left seems both most dense and the darkest, 
a low pc1 seems to contibute alot toward lower VCPP

Pov1 = 0.2502 Pov2 = 0.1693



```{r pressure, echo=FALSE}
df = read.csv("communities.csv") #reload the data.
summary(df)

#scale and split 50/50
df = scale(df, TRUE, TRUE)
set.seed(12345)

n <- dim(df)[1]
id <- sample(1:n,floor(n*0.5))
df_train <- data.frame(df[id,])
df_test <- data.frame(df[-id,])


lr = lm(ViolentCrimesPerPop ~ .,df_train)

train.pred = predict(lr, df_train)
test.pred = predict(lr, df_test)

summary(lr)

sur_train = mean((train.pred - df_train$ViolentCrimesPerPop) ^ 2)
sur_test = mean((test.pred - df_test$ViolentCrimesPerPop) ^ 2)

sur_train
sur_test

```

```{r pressure, echo=FALSE}
train_error <<- numeric(0)
test_error <<-numeric(0)

set.seed(12345)

cost <- function(theta, train, acc_train, test, acc_test){
  pred_train = train %*% theta
  pred_test = test %*% theta
  
  
  mse_train = mean((acc_train-pred_train)^2)
  train_error <<- append(train_error,mse_train)
  
  mse_test = mean((acc_test - pred_test)^2)
  test_error <<- append(test_error,mse_test)

  return(mse_train)
}



trainy = as.matrix(df_train[,1:(dim(df_train)[2]-1)])
acc_train = as.matrix(df_train['ViolentCrimesPerPop'])

testy = as.matrix(df_test[,1:(dim(df_test)[2]-1)])
acc_test = as.matrix(df_test['ViolentCrimesPerPop'])



theta =numeric(dim(trainy)[2])
theta = as.matrix(theta)


opt = optim(par=theta,fn=cost,  train = trainy ,acc_train = acc_train, test=testy, acc_test=acc_test,method = "BFGS")

opt_theta = opt$par

train_opt_error = opt$value

test_opt_error = mean((acc_test - (testy %*% opt_theta))^2)


train_opt_error
sur_train
test_opt_error
sur_test

bl = c(TRUE,rep(FALSE,500))

rest_train = train_error[bl]
rest_test = test_error[bl]

test_min_ind = which(test_error==min(test_error))
test_min_ind
min(test_error)

test_opt_ind = which(test_error==test_opt_error)
test_opt_ind
test_opt_error


plot(rest_train, xlim=c(0,length(rest_train)), ylim=c(0,1.5), col = "blue")
points(rest_test, col="red")
lines(c(0,1000), rep(sur_train, 2), col="blue")
lines(c(0,1000), rep(sur_test, 2), col="red")

```
Min test_error and the early stopping point appears at index 2183 with mse of 0.377.
The results from the 3 task and the computed optimal values in this exercise are basically the same both in the plot and the printed results.

