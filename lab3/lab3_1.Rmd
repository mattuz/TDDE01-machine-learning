---
title: "lab3"
output: html_document
date: "2022-12-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Task 1

Setup
```{r, warning=FALSE, echo=FALSE}
set.seed(1234567890)
library(geosphere)
stations <- read.csv("stations.csv")
temps <- read.csv("temps50k.csv")

date <- as.Date("2013-11-04") # The date to predict (up to the students)
filtered_temps <- temps[temps$date < as.Date(date),] #Filter the tempratures to discard irrelevant dates.

st <- merge(stations,filtered_temps,by="station_number")
# These three values are up to the students 
h_distance <- 40000 #Unsure how much we want to consider stations further away. 
h_date <- 9
h_time <- 3
a <- 58.4274 # The point to predict (up to the students) #latitud
b <- 14.826 #longitud
pos_vec <- cbind(b,a)

times <- c("04:00:00", "06:00:00", "08:00:00",
           "10:00:00","12:00:00","14:00:00",
           "16:00:00","18:00:00","20:00:00",
           "22:00:00", "24:00:00")
times_numbers <-c(4,6,8,10,12,14,16,18,20,22,24) #for the plot
temp <- vector(length=length(times))




```


Calculations for relative distances in location, date (day) and time (hours). 
```{r, warning=FALSE, echo=FALSE}

# Studentsâ€™ code here
#physical distance with distHaversine
st_loc<-cbind(st$longitude,st$latitude)
dist_hav<-distHaversine(p1=pos_vec,p2=st_loc)
m<-cbind(dist_hav)

#Gaussian Kernel
#(x_* - x_i)/h from lectures
#diff represents (x_* - x_i)
gaussian_kernel<-function(diff, h_val) {
  
  u <- diff/h_val
  return(exp(-u*u))
}


relative_day_dist <- function(d1,d2){
  diff<- as.Date(d1) - as.Date(d2) #Difference between our date and the date we're comparing (in days).
  return (as.numeric(diff))
}

relative_hour_dist <- function(time1, time2) {
  time_obj1 <-strptime(time1,format="%H:%M:%S") #Create time object so that we can extract hour
  time_obj2 <-strptime(time2,format="%H:%M:%S")
  h1<-as.integer(format(time_obj1,"%H")) #take the hour value as an integer
  h2<-as.integer(format(time_obj2,"%H"))
  # Convert hours to minutes
  minute1 <- h1 * 60
  minute2 <- h2 * 60

  # Compute the absolute difference in minutes
  minute_diff <- abs(minute1 - minute2)

  # Compute the relative distance in hours
  hour_diff <- minute_diff / 60

  return(hour_diff)
}

```



Calculations with sum of kernels. 
```{r, warning=FALSE, echo=FALSE}

#Calculations
predictions = rep(0,11)
k_distance <- gaussian_kernel(dist_hav,h_distance)
k_days <- gaussian_kernel(relative_day_dist(date,filtered_temps$date),h_date)


for (i in 1:length(temp)) {
  rel_h<-relative_hour_dist(times[i],filtered_temps$time)
  k_time <- gaussian_kernel(relative_hour_dist(times[i],filtered_temps$time),h_time)
  k_sum <- cbind(k_distance + k_days + k_time)
  k_sum <- (k_sum/sum(k_sum)) # Normalize the values in the k_sum matrix by dividing each element by the sum of the elements in each row
  weighted_temps <- k_sum * filtered_temps$air_temperature #get weighted temperatures
  
  predictions[i] <- sum(weighted_temps)

  
}
plot(times_numbers,predictions,type="o",xlab = "Time of day (hours)",ylab = "Predicted temp",main = "Prediction of temperature using sum")


#Used to look at h values
#plot(rel_h,k_time)
#plot(dist_hav,k_distance,xlim=c(0,100000))
#plot(relative_day_dist(date,filtered_temps$date),k_days,xlim=c(0,100))



```
These values look very reasonable. Looking at the curve going from colder at the earlier and later hours, while having higher temperatures at the middle of the day. November of 2013 was a very cold month in general, so having a prediction of +6 C is not unreasonable. 


```{r, warning=FALSE, echo=FALSE}
predictions2 = rep(0,11)
k_distance <- gaussian_kernel(dist_hav,h_distance)
k_days <- gaussian_kernel(relative_day_dist(date,filtered_temps$date),h_date)



for (i in 1:length(temp)) {
  rel_h<-relative_hour_dist(times[i],filtered_temps$time)
  k_time <- gaussian_kernel(relative_hour_dist(times[i],filtered_temps$time),h_time)
  k_sum <- cbind(k_distance * k_days * k_time)
  k_sum <- (k_sum/sum(k_sum)) # Normalize the values in the k_sum matrix by dividing each element by the sum of the elements in each row
  weighted_temps <- k_sum * filtered_temps$air_temperature #get weighted temperatures
  
  predictions2[i] <- sum(weighted_temps)

  
}
plot(times_numbers,predictions2,type="o",xlab = "Time of day (hours)",ylab = "Predicted temp",main = "Prediction of temperature using mult")



```
This graph looks a bit more unclear. It's difficult to interpret if there's something wrong with how the data has been divided when multiplying, since the curve is not distributed like a bell curve. 

The reason for this graph being less "well distributed" is because the multiplied kernels will give more weight to the higher elements in the kernels, while suppressing the lower ones. This means that values that are not very close to the points we're looking at will not be considered nearly as much (even if they're already not being considered much). 

The summed kernel graph gives equal weights to all values which will give our predictions more "real" data to use, since values a bit further away from our initial ones will still be considered. In this case these values are very relevant, since weather predictions (more specifically, temperature predictions) require a lot of data, which should be distributed over time (and not only looking at the exact same day/time/location as what we're trying to predict). 

Task 2

Error estimates:
```{r, warning=FALSE, echo=FALSE}


library(kernlab)
set.seed(1234567890)

data(spam)
foo <- sample(nrow(spam))
spam <- spam[foo,]
spam[,-58]<-scale(spam[,-58])
tr <- spam[1:3000, ]
va <- spam[3001:3800, ]
trva <- spam[1:3800, ]
te <- spam[3801:4601, ] 

by <- 0.3
err_va <- NULL
for(i in seq(by,5,by)){
  filter <- ksvm(type~.,data=tr,kernel="rbfdot",kpar=list(sigma=0.05),C=i,scaled=FALSE)
  mailtype <- predict(filter,va[,-58])
  t <- table(mailtype,va[,58])
  err_va <-c(err_va,(t[1,2]+t[2,1])/sum(t))
}

filter0 <- ksvm(type~.,data=tr,kernel="rbfdot",kpar=list(sigma=0.05),C=which.min(err_va)*by,scaled=FALSE)
mailtype <- predict(filter0,va[,-58])
t <- table(mailtype,va[,58])
err0 <- (t[1,2]+t[2,1])/sum(t)
print("Error 0")
err0

filter1 <- ksvm(type~.,data=tr,kernel="rbfdot",kpar=list(sigma=0.05),C=which.min(err_va)*by,scaled=FALSE)
mailtype <- predict(filter1,te[,-58])
t <- table(mailtype,te[,58])
err1 <- (t[1,2]+t[2,1])/sum(t)
print("Error 1")

err1

filter2 <- ksvm(type~.,data=trva,kernel="rbfdot",kpar=list(sigma=0.05),C=which.min(err_va)*by,scaled=FALSE)
mailtype <- predict(filter2,te[,-58])
t <- table(mailtype,te[,58])
err2 <- (t[1,2]+t[2,1])/sum(t)
print("Error 2")
err2

filter3 <- ksvm(type~.,data=spam,kernel="rbfdot",kpar=list(sigma=0.05),C=which.min(err_va)*by,scaled=FALSE)
mailtype <- predict(filter3,te[,-58])
t <- table(mailtype,te[,58])
err3 <- (t[1,2]+t[2,1])/sum(t)

print("Error 3")
err3

```

# Questions

# 1. Which filter do we return to the user ? filter0, filter1, filter2 or filter3? Why?

The filter we return is filter1. Because the SVM model is trained on trianing data (tr) and validated on validation data (va). Then we should use the optimal err_va to make prediction on the test data. Using ksvm on training data and not any other. In general you do your training on your training set, evalutate its performance on the validation set, and then use the best model to predict on the test dataset. 

# 2. What is the estimate of the generalization error of the filter returned to the user? err0, err1, err2 or err3? Why?

it is err1 = 0.08489388. Filter0 gives low error estimate due to the fact that it is filtered on validation, the same way we choose the optimal err_va. Filter3 gives the lowest error estimate because of the the model is trained on the same data it is predicted on. As for filter1 and filter2, they give similar error estimates. Filter2 error rate is slightly lower due to the fact that it is trained on a larger data set (training and validation), where filter1 is only trained on training data.

# 3. Implementation of SVM predictions.


```{r, echo=FALSE}
# Get the indices of the support vectors in the SVM classifier
sv <- alphaindex(filter3)[[1]]

# Get the coefficients of the support vectors in the SVM classifier
co <- coef(filter3)[[1]]

# Get the bias term of the SVM classifier and negate it
inte <- -b(filter3)

# Create an RBF kernel with a standard deviation of 0.05
rbfkernel <- rbfdot(sigma = 0.05)

# Initialize an empty vector to store the predicted values
k <- c()

# Loop over the first 10 rows of the spam dataset
for(i in 1:10) { 
  
  # Initialize a variable to store the predicted value for the current row
  k2 <- 0
  
  # Loop over each support vector
  for(j in 1:length(sv)) {
    
    # Apply the RBF kernel to the jth support vector and the ith row of the spam dataset. We unlist the matrixes to perform the calculations.
    f <- rbfkernel(unlist(spam[sv[j], -58]), unlist(spam[i, -58]))
    
    # Update the predicted value for the current row by adding the product of the jth coefficient and the value of the kernel. F is a 1x1 matrix.
    k2 <- k2 + co[j] * f[1]
  }
  
  # Append the predicted value for the current row to the k vector
  k <- c(k, k2 + inte)
}

# Print the k vector
k

# Use the predict function to make predictions on the first 10 rows of the spam dataset using the trained SVM classifier
prediction = predict(filter3, spam[1:10, -58], type = "decision")

plot(k, col = "red")
lines(prediction)

```
The red dotted points is the predicted values that generated from the linear combination for filter3. The lines is the predictions from the predict function. 

Task 3



